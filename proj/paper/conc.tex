
\section{Future Work} \label{sec:future}

This work touches on the language design aspects of PPLs
in general. We also discuss the applicability of such PPLs
to a specific game (Dominion). In Section \ref{sec:future:dominion}
we discuss Dominion-specific future work. In Section \ref{sec:future:PPL}
we discuss possible future extensions of the linguistic analyses from
Section \ref{sec:meta-analysis}.

\subsection{Dominion} \label{sec:future:dominion}
%On the latter, future work
%will involve:

This work has demonstrated that modeling Dominion is, by itself,
a difficult task. The modeler must have both an intimate knowledge
of Dominion's mechanics and some level of experience using PPLs.
This is further complicated by the fact that games like Dominion
are described most naturally in a recursive form. Future work should
therefore include a guarantee of correctness of the models presented
in this paper. We are confident in the MCMC techniques used in this
paper. We are however less confident in the exact numeric results
shown in the distributions in the results section. The results
presented do cross-validate with existing beliefs, we should however
perform a more statistically rigorous analysis of these
results.

This future analysis could involve computing values for the
intercepts and slopes of the three distributions in Figure
\ref{fig:rejection-sampling}. We believe this slope $m$ can be used
to compute the relative balance between the cards $X$ and $Y$ in
our greedy model. Namely that balance is proportional to
$1 / abs(m)$. A slope of exactly $m = 0$ would mean the cards
$X$ and $Y$ are perfectly balanced (infinite balance). In
this case we have a uniform conditional probability distribution
over $p_0$.

In contrast
a slope approaching $m = \pm \infty$ indicates either $X$ or $Y$
completely dominates the other (perfectly imbalanced). The
conditional distribution we infer should, for perfect imbalance,
approach the form of a dirac-delta function:

$$P(p_0 | t_e = t_e') \rightarrow \left\{
  \begin{array}{lr}
    \delta(0.0) & : \textrm{ as } m \rightarrow -\infty \\
    \delta(1.0) & : \textrm{ as } m \rightarrow +\infty
  \end{array}
\right.
$$

In similar fashion to the slope $m$, we believe the intercept $b$ to be
an absolute measure of the balance between cards $X$ and $Y$.
Future work will involve both testing these hypotheses about
the form of the distributions and quantifying the distributions
for interesting conditions.

We hope to make analyses like this one more friendly to `game design'
domain experts who are not steeped in the statistical and
linguistic aspects of the analysis. Such a goal is best suited to
a domain-specific probabilistic programming language. This DSL
would provide built-in functionality for computing metrics like
\emph{balance} from the inferred conditional distributions.
The output of programs in the DSL would be a set of statistics
and visualizations of interest to a game designer. This output
is in lieu of (or in addition to) the probability distribution(s)
printed by existing general-purpose PPLs.
% 3 levels of meta (Language    -> Probabilistic -> Game)
%                  (Linguistics -> Statistics    -> Design)

The tools and support we envision a game designer having
in conjunction with a probabilistic DSL comprise:

\begin{itemize}
\item Automated analysis of the form of inferred probability distributions
      using existing curve fitting algorithms.
\item Support for analysis of multiple variables at the same time
      \begin{itemize}
      \item Coordinated multiple views visualization of the conditioned
            distributions over the latent variables.
      \end{itemize}
\end{itemize}

% TODO / future work: compare a linear fit of the distribution with
% an exponential one. discuss / think about how we might discuss why
% the underlying game mechanics and our choices for $X$ and $Y$ might
% make either a linear or exponential fit inherently more meaningful
% (e.g. what would the parameters to the exponential model of the
% probability distribution correspond to in terms of balance / interaction
% of the two cards - how can we quantify specific interactions between
% cards. an interaction between two cards on a player's turn in Dominion
% is probabilistically linked to both the total number of turns in the
% game and any latent variables we are interested in

These tools and features will compliment Dominion-specific future
work comprising:

\begin{itemize}
\item Implementation of more Dominion-specific heuristics.
\item Designing heuristics capable of maintaining probabilistic models
      corresponding to belief states. What is the feasibility of recursive
      use of probabilistic models in existing PPLs?
\item Cross-validation with currently held beliefs of human Dominion
      players / domain experts. \cite{human-card-comparisons}
\item Applying Machine Learning algorithms to publicly available Dominion
      data sets. \cite{dominion-data-sets}
\item Design of a probabilistic inference engine to determine
      {\bf balanced} sets of cards to play with.
\end{itemize}

\subsection{PPL Design} \label{sec:future:PPL}
%On the PPL design side, we would like to further explore:

Hakaru does not enforce any sort of type abstractions related to latent
and observable variables. This makes for easy implementation of probabilistic
models which can be used to answer various questions regardless of the
exact interpretation of the variables in the question. This however in the
best case requires a reader to implicitly (e.g. by reading code comments)
determine which variables are latent or observed on a particular run of
the program. In the worst case it can result in design flaws in probabilistic
models which invalidate the results.

One possible solution to this is for PPLs like Hakaru
to strictly enforce the primitive probabilistic types (observable,
latent, ...) of a variable using an existing strongly-typed host language.
The PPL then defines a library of combinator functions for transforming
and composing model variables. For example the `+' combinator for adding
a latent and an observable variable together would result in a latent
variable. The Haskell type signature might look something like:

\begin{minted}[fontsize=\footnotesize]{haskell}
(+) :: (Num a, Num b, Num c)
    => Latent a -> Observable b -> Latent c
\end{minted}

Such abstractions would have allowed
us to express our inference question (Question 2\ignore{\ref{q:inference}}) as an
unambigous Haskell function. In particular the variable $p_0$ is used in
one context as a known parameter to the model, and in another context as
the latent variable we would like to infer. While our inference question
is relatively simple (single variable), keeping track of which variables
are observable and which are latent becomes error-prone when we look at
inference questions involving multiple parameters of interest.

%Similarly, `hyper-parameters' to a probabilistic model have a much richer
%structure than their name suggests at first glance. In the context of a
%probabilistic model, this work takes hyper-parameter to mean a parameter
%which changes the structure of the computations in the model
%but not the variables being conditioned on.

% Need some sort of combinator library / monadic abstraction which
% keeps track of the level of abstraction you want to describe your
% model at. "Hyper-parameter" is an ambiguous name for something
% which your probabilistic model does not condition on / 'simply'
% indirectly changes the structure of the probabilistic computation
% -- for a probabilistic model to be modular in a way that e.g. both
% -- game designers and game players can use, the probabilistic
% -- abstractions need to encompass some sort of naming scheme /
% -- distinction between the level of abstraction at which a parameter
% -- resides. How domain-specific are these abstractions? How universal
% -- is the distinction between e.g. a hyper-parameter which changes
% -- the fundamental structure of an expression in the condition of
% -- an if-statement as compared to a model hyper-parameter which
% -- changes the value of a random variable we are conditioning on.
%    Clearly there are both linguistic and probabilistic implications of
%    of how we classify these parameters.

% $p_0$ is a known parameter in question #1 whereas it is a latent variable
% in the inference question.

In the immediate future we would like to investigate:

\begin{itemize}
\item The useability of Church, Figaro, probability monad, and other
      PPLs in the context of this work.
\item The utility of a domain specific language for modeling deckbuilding
      games. What do we gain from card-game specific probabilistic
      abstractions?
\end{itemize}

%\section{Conclusions} \label{sec:conc}

\section{Acknowledgements} \label{sec:ack}

